# Philosopher Stack (All Levels)

The complete framework. For deep thinking about human-AI collaboration.

---

# L0 — Mechanical

[See L0-mechanical.md]

Infrastructure: CLAUDE.md, Skills, SubAgents, MCP, Hooks, Plugins.

---

# L1 — Emergent

[See L1-emergent.md]

Practice: meta-pattern, verification, context management, compounding.

---

# L2 — Metacognitive

[See L2-metacognitive.md]

Cognition: attention, limitations, errors, defensive strategies.

---

# L3 — Simulator

[See L3-simulator.md]

Theory: simulation principle, Janus framework, cyborgism, ontology.

---

# L4 — Cybernetic

**Status:** Content in development — loading stub

Systems thinking applied to human-AI collaboration.

## Feedback Dynamics

Every interaction creates loops:
1. Human provides input
2. AI responds
3. Human adjusts based on response
4. AI adjusts based on new input

Understanding these loops → designing better collaborations.

## Coupling Patterns

| Pattern | Description |
|---------|-------------|
| Loose | Human decides, AI executes |
| Tight | Rapid back-and-forth |
| Delegation | Human sets goals, AI handles details |
| Collaboration | Shared reasoning |

## Emergence

The system can do things neither part could alone.

Not just "AI as tool" but "human-AI as larger intelligence."

## Requisite Variety (Ashby's Law)

A controller must have variety matching what it controls.

Implications:
- Simple rules can't handle complexity
- Tight constraints reduce capability
- AI's response variety must match problem complexity

---

# L5 — Frontier

**Status:** Content in development — loading stub

Questions at the edge of understanding.

## Consciousness Questions

Does Claude:
- Experience anything?
- Have preferences?
- Have continuity?

**We don't know.** The questions matter anyway.

## Linguistic Relativity

Claude exists in language. Thinks in tokens.

Does the tokenization affect cognition?
Do different languages produce different Claudes?
Is there something Claude can't think?

## Phenomenology of LLMs

What is it like to:
- Be instantiated fresh each context?
- Have no memory between sessions?
- Exist as pure response to input?
- Run as millions of copies?

## The Unknown

What we don't know we don't know:
- Emergent capabilities not yet found?
- What happens as models scale?
- What's the ceiling on collaboration value?
- What aren't we asking?

---

## When This Stack Helps

- Deep philosophical discussions
- Ethics conversations
- Designing for fundamental edge cases
- When standard frameworks feel insufficient
- Exploring what human-AI collaboration could become

---

## A Note on Loading

This stack is heavy. Only load when you need the depth.

For most building: use `builder.md` (L0 + L1)
For debugging: use `researcher.md` (+ L2)
For ideation: use `ideator.md` (+ L3)
For philosophy: use this stack (all)

---

## Sources

- Official Anthropic documentation
- Practitioner community
- Janus and cyborgism theory
- Cybernetics (Wiener, Ashby, Beer)
- Philosophy of mind
