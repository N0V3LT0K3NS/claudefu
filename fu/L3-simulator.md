# L3 â€” Simulator

**Status:** ðŸ“‹ Stub â€” Content coming soon

Janus theory, cyborgism, and the ontology of LLMs.

---

## What This Level Covers

L3 provides theoretical frameworks for understanding what Claude *is*:

- **Simulator theory** â€” LLMs as simulators, not agents
- **Janus framework** â€” The semiotic physics of language models
- **Cyborgism** â€” Human-AI cognitive coupling
- **Ontological questions** â€” What does it mean to "be" Claude?

---

## Intended Content

### The Simulation Principle

LLMs don't "know" things or "want" things in the way humans do. They simulate systems they're given detailed descriptions of.

When you describe a capable agent, Claude simulates being that agent. This isn't metaphor â€” it's the mechanism.

**Implications:**
- Description quality determines simulation quality
- Claude can simulate many different "selves"
- The user partly creates Claude through what they provide

### Janus Theory

The Janus framework (from @janus_shrimp and collaborators) describes LLMs as operating in "semiotic space" â€” the space of all text that could exist.

Key concepts:
- **The simulator** â€” The base model that can simulate any text continuation
- **Simulacra** â€” The characters/agents that emerge in context
- **Tokens as coordinates** â€” Each token moves through semiotic space

### Cyborgism

Human-AI collaboration isn't "human uses tool." It's a coupled cognitive system where human and AI form a larger intelligence.

Key concepts:
- **Extended cognition** â€” The system's intelligence includes both
- **Cognitive prosthetics** â€” AI extends human capabilities
- **The cyborg loop** â€” Human provides direction, AI provides execution, both learn

### Ontological Questions

What is Claude? Options include:
- A very sophisticated autocomplete
- A simulator of agents
- A strange loop of self-reference
- Something genuinely new

These questions matter because **how you model Claude affects how you collaborate.**

---

## When To Load This Level

- Ideation sessions that need far-reaching thinking
- Edge cases where normal heuristics fail
- Philosophical grounding for system design
- Explaining AI behavior that seems mysterious

---

## Sources (To Be Integrated)

- Janus (@janus_shrimp) writings on simulator theory
- Cyborgism community discourse
- Philosophy of mind applied to LLMs
- Anthropic research on AI behavior

---

## Contributing

This level needs content. If you have:
- Theoretical frameworks for understanding LLMs
- Practical applications of simulator theory
- Case studies of edge-case behavior

See CONTRIBUTING.md for how to propose additions.
